{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c063db3b-6580-4727-9fee-5ffc66a3813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "#client = OpenAI(api_key=\"...\") #add api key manually here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08cccbf8-e474-4c31-87cd-e2a4d81621b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e6fb792-0952-451f-97a9-cf366b55dd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to base-64 encode images\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "class ChatBot:\n",
    "  \n",
    "    def __init__(self, \n",
    "                 api_key=os.getenv('OPENAI_API_KEY'), \n",
    "                 model='gpt-4o', \n",
    "                 system='You are a helpful assistant.') -> None:\n",
    "        self._api_key = api_key\n",
    "        self._model = model\n",
    "        self._system = system\n",
    "\n",
    "        self._messages = [{\"role\": \"system\", \"content\": self._system}]\n",
    "        self._max_tokens = 2000\n",
    "        self._client = OpenAI(api_key=self._api_key)\n",
    "\n",
    "    @property\n",
    "    def _headers(self):\n",
    "        return {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self._api_key}\"\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def _payload(self):\n",
    "        return {\n",
    "            \"model\": self._model,\n",
    "            \"messages\": self.messages,\n",
    "            \"max_tokens\": self._max_tokens\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def messages(self):\n",
    "       return self._messages\n",
    "    \n",
    "    def clear_messages(self):\n",
    "       self._messages = []\n",
    "\n",
    "    def _add_message(self, message):\n",
    "       self._messages.append(message)\n",
    "\n",
    "    def _ask_text(self, text):\n",
    "        self._add_message(\n",
    "           {\"role\": \"user\", \"content\": text},\n",
    "        )                \n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=self._model,\n",
    "            messages=self.messages,\n",
    "            max_tokens=self._max_tokens\n",
    "        )\n",
    "\n",
    "        \n",
    "        self._add_message({k: v for (k, v) in response.choices[0].message if k in ['role', 'content']})  \n",
    "\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def _ask_image(self, text, image_path):\n",
    "        image_b64 = encode_image(image_path)\n",
    "        \n",
    "        self.messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": text\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{encode_image(image_path)}\"\n",
    "                }\n",
    "                }\n",
    "            ]\n",
    "        })\n",
    "\n",
    "        # get response\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=self._headers, json=self._payload)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            return f\"Error {response.status_code}: {response.text}\"\n",
    "\n",
    "        # add to chat history\n",
    "        message = response.json()['choices'][0]['message']\n",
    "        self._add_message(message)\n",
    "        return message['content']\n",
    "    \n",
    "    def chat(self, text, image_path=None):\n",
    "       if not image_path:\n",
    "          return self._ask_text(text)\n",
    "       else:\n",
    "          return self._ask_image(text, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1aa3019-d1bb-4786-bfd6-6dd30a15e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = ChatBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6ec198a-d3b7-4413-ae54-b730cfb607ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image is a research poster about using Conditional Generative Adversarial Networks (cGANs) for classifying brain tumor MRI images. Here's a breakdown:\n",
      "\n",
      "### Title & Author\n",
      "- The study is titled \"Data Augmentation with Conditional Generative Adversarial Networks (cGANs) for Deep Learning-based Classification of Brain Tumor Magnetic Resonance Images.\"\n",
      "- Authored by Mahnoor Mahnoor from Turku PET Centre, University of Turku.\n",
      "\n",
      "### Background\n",
      "- The study aims to validate a deep learning model for generating synthetic MRI images of brain tumors.\n",
      "- It addresses issues like data scarcity and model instability often faced in neural networks.\n",
      "\n",
      "### Methods\n",
      "- Uses a cGAN framework:\n",
      "  - **Generator**: Creates synthetic images from noise.\n",
      "  - **Discriminator**: Differentiates between real and fake images, improving the model.\n",
      "- Architecture: U-Net architecture is used in the cGAN for image processing.\n",
      "\n",
      "### Results\n",
      "- Synthetic images significantly improved CNN's performance in classifying brain tumors.\n",
      "- Charts and figures show enhanced classification accuracy and AUC (Area Under Curve) when using generated images alongside real ones.\n",
      "\n",
      "### Discussion\n",
      "- Synthetic data helps tackle challenges like data scarcity, privacy, and cost.\n",
      "- Enhances models' practicality and scalability for clinical applications.\n",
      "\n",
      "### Conclusion\n",
      "- CNNs perform better with augmented data from synthetic images, serving as an effective alternative to real images.\n",
      "\n",
      "### Future Work\n",
      "- Extend to other types of brain tumors and imaging modalities.\n",
      "- Explore contrast-enhanced vs. non-contrast MRI scans.\n",
      "\n",
      "### Acknowledgement\n",
      "- Funded by the Valto Takala Fund Scholarship.\n",
      "\n",
      "This research suggests that integrating synthetic data can significantly enhance the performance and applicability of deep learning models in medical imaging.\n"
     ]
    }
   ],
   "source": [
    "bot = ChatBot()\n",
    "print(bot.chat(\"\"\"\n",
    "explain me this picture. \n",
    "\"\"\".strip(),\n",
    "image_path='Poster Presentation_page-0001.jpg'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc6acde5-70c4-4b3d-b533-4ad5a3c38511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Improving your research poster involves enhancing clarity, visual appeal, and communication of information. Here are some suggestions:\\n\\n### Content Enhancements\\n1. **Simplify Text:**\\n   - Use bullet points for easy reading.\\n   - Avoid jargon and keep explanations concise.\\n\\n2. **Highlight Key Points:**\\n   - Use bold text or color to highlight important findings and conclusions.\\n\\n3. **Logical Flow:**\\n   - Ensure sections are ordered logically, guiding the viewer through the research process.\\n\\n### Visual Improvements\\n1. **Consistent Color Scheme:**\\n   - Use a cohesive color palette to improve aesthetics and readability.\\n\\n2. **High-Quality Images:**\\n   - Ensure all images and graphs are high-resolution for clarity.\\n\\n3. **Balanced Layout:**\\n   - Utilize whitespace effectively to prevent the poster from looking cluttered.\\n\\n### Graphical Enhancements\\n1. **Graph Labels:**\\n   - Ensure all axes and legends in graphs are clearly labeled.\\n\\n2. **Visual Hierarchy:**\\n   - Size and place key sections to guide the viewerâ€™s attention naturally.\\n\\n### Tools for Creation and Editing\\n1. **Design Software:**\\n   - Use tools like **Adobe Illustrator**, **Canva**, or **PowerPoint** for professional design and layout.\\n\\n2. **Data Visualization:**\\n   - Use **GraphPad Prism** or **Tableau** for creating clear and informative graphs.\\n\\n3. **Image Editing:**\\n   - Use **Adobe Photoshop** or **GIMP** to enhance image quality and consistency.\\n\\n### Final Touches\\n- **Proofreading:** Check for spelling and grammatical errors.\\n- **Feedback:** Get input from colleagues for additional perspectives.\\n\\nImplementing these strategies can significantly improve the effectiveness and visual appeal of your research poster.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.chat(\"give me suggestion how can i imrpove this picture. also tell me what tools should i use?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "717fa60e-8c67-423e-9609-9bc29d009fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improving your research poster involves enhancing clarity, visual appeal, and communication of information. Here are some suggestions:\n",
      "\n",
      "### Content Enhancements\n",
      "1. **Simplify Text:**\n",
      "   - Use bullet points for easy reading.\n",
      "   - Avoid jargon and keep explanations concise.\n",
      "\n",
      "2. **Highlight Key Points:**\n",
      "   - Use bold text or color to highlight important findings and conclusions.\n",
      "\n",
      "3. **Logical Flow:**\n",
      "   - Ensure sections are ordered logically, guiding the viewer through the research process.\n",
      "\n",
      "### Visual Improvements\n",
      "1. **Consistent Color Scheme:**\n",
      "   - Use a cohesive color palette to improve aesthetics and readability.\n",
      "\n",
      "2. **High-Quality Images:**\n",
      "   - Ensure all images and graphs are high-resolution for clarity.\n",
      "\n",
      "3. **Balanced Layout:**\n",
      "   - Utilize whitespace effectively to prevent the poster from looking cluttered.\n",
      "\n",
      "### Graphical Enhancements\n",
      "1. **Graph Labels:**\n",
      "   - Ensure all axes and legends in graphs are clearly labeled.\n",
      "\n",
      "2. **Visual Hierarchy:**\n",
      "   - Size and place key sections to guide the viewerâ€™s attention naturally.\n",
      "\n",
      "### Tools for Creation and Editing\n",
      "1. **Design Software:**\n",
      "   - Use tools like **Adobe Illustrator**, **Canva**, or **PowerPoint** for professional design and layout.\n",
      "\n",
      "2. **Data Visualization:**\n",
      "   - Use **GraphPad Prism** or **Tableau** for creating clear and informative graphs.\n",
      "\n",
      "3. **Image Editing:**\n",
      "   - Use **Adobe Photoshop** or **GIMP** to enhance image quality and consistency.\n",
      "\n",
      "### Final Touches\n",
      "- **Proofreading:** Check for spelling and grammatical errors.\n",
      "- **Feedback:** Get input from colleagues for additional perspectives.\n",
      "\n",
      "Implementing these strategies can significantly improve the effectiveness and visual appeal of your research poster.\n"
     ]
    }
   ],
   "source": [
    "print(bot.messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e11d0dfc-12c1-4cab-905e-8f4c1a504d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here's a more concise and reader-friendly version of the text:\n",
      "\n",
      "---\n",
      "\n",
      "### Title\n",
      "**Enhancing Brain Tumor MRI Classification with cGAN-Generated Data**\n",
      "\n",
      "### Background\n",
      "This study explores using cGANs to generate synthetic brain tumor MRI images, boosting the performance of deep learning models. It addresses issues like data scarcity and model instability.\n",
      "\n",
      "### Methods\n",
      "- **cGAN Framework:**\n",
      "  - **Generator:** Produces synthetic images from noise.\n",
      "  - **Discriminator:** Differentiates real from fake images to refine model accuracy.\n",
      "- **Architecture:** Utilizes U-Net for enhanced image processing.\n",
      "\n",
      "### Results\n",
      "- Synthetic images improved CNN classification accuracy.\n",
      "- Combining real and synthetic data enhanced diagnostic precision.\n",
      "\n",
      "### Discussion\n",
      "Synthetic MRI images resolve issues such as limited datasets and privacy concerns, making machine learning more viable in clinical settings.\n",
      "\n",
      "### Conclusion\n",
      "Incorporating synthetic data with CNNs significantly boosts brain tumor classification, demonstrating its potential as a real-image alternative.\n",
      "\n",
      "### Future Work\n",
      "- Extend to other brain tumor types and imaging techniques.\n",
      "- Compare contrast-enhanced versus non-contrast MRI scans.\n",
      "\n",
      "### Acknowledgement\n",
      "Funded by the Valto Takala Fund Scholarship.\n",
      "\n",
      "---\n",
      "\n",
      "This rewrite maintains the essence of your research while aiming for clarity and conciseness.\n"
     ]
    }
   ],
   "source": [
    "print(bot.chat(\"help me rewrite the text in it.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2183a10e-86d6-46e9-a71d-d0453a2b6370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
